{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "I used an ensemble model to reduce overfitting of the model since there are many trees 'deciding' the outcome (individual trees are prone to overfitting). This model was used because of convenience, since numerical data are not needed to be standardized, in which $\\mu$ and $\\sigma$ determined from training data are needed to be used again in standardizing cross validation and test sets.\n",
    "\n",
    "To find a good parameter, I did 10-fold cross validation of the training data, and searched a **very small** region in the parameter space (to save running time). The evaluation metric used is f1 score (which uses the precision and recall) which is more applicable for skewed labels than using accuracy score (since you can guess that y is all 'no' and you can still get a high accuracy score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_findparams(features, labels, model, params):\n",
    "    \"\"\"\n",
    "    finds the optimal parameters of the model from 5-fold cross validation,\n",
    "    scoring uses f1 score since the labels are skewed towards y=0\n",
    "    \"\"\"\n",
    "    # search parameter space for optimal parameters\n",
    "    grid = GridSearchCV(model, param_grid=params, cv=5, scoring=make_scorer(f1_score, average='binary'))    \n",
    "    # Fit the grid search to the data\n",
    "    grid.fit(features, labels)\n",
    "    return grid #attributes: grid.best_params_, grid.best_estimator_\n",
    "\n",
    "def model_predict(estimator, features, labels):\n",
    "    preds = estimator.predict(features)\n",
    "    score = f1_score(y_true=labels, y_pred=preds, average='binary')    \n",
    "    return preds, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discard 'duration', 'pdays' (due to extreme skewness), and the external factors. I did not consider external factors since it is not indicated when are they taken and how are they connected to each individual client (data-wise). \n",
    "\n",
    "Initially, we get a f1 score of 0.31 and 88.8% classification accuracy (we expect that classification accuracy is higher because the labels are skewed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3067669172932331\n",
      "0.8880796309783928\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "    \n",
    "    del df['duration']\n",
    "    del df['pdays']\n",
    "    del df['emp.var.rate']\n",
    "    del df['cons.price.idx']\n",
    "    del df['cons.conf.idx']\n",
    "    del df['euribor3m']\n",
    "    del df['nr.employed']\n",
    "\n",
    "    # log transform numerical data\n",
    "    df['age'] = np.log(df.age)\n",
    "\n",
    "    # Encode categorical data\n",
    "    # combine 'retired', 'student' as 'outside' (i.e. outside the working sector)\n",
    "    # combine 'housemaid', 'services' as 'services'\n",
    "    # combine 'admin.', 'management' as 'admin\n",
    "    # combine 'entrepreneur', 'self-employed' as 'self-employed'\n",
    "    old_job_keys = ['unknown', 'unemployed', 'retired', 'student', 'blue-collar', 'technician', 'housemaid', 'services', 'admin.', 'management','entrepreneur', 'self-employed']\n",
    "    new_job_keys = ['unknown', 'unemployed', 'outside', 'outside', 'blue-collar', 'technician', 'services', 'services', 'admin', 'admin', 'self-employed', 'self-employed']\n",
    "    job_grp_dict = dict(zip(old_job_keys, new_job_keys))\n",
    "    df['job'] = df['job'].map(job_grp_dict)\n",
    "    dummy_job = pd.get_dummies(df[['job']])\n",
    "    df = pd.concat([df, dummy_job], axis=1)\n",
    "    del df['job']\n",
    "\n",
    "    dummy_marital = pd.get_dummies(df[['marital']])\n",
    "    df = pd.concat([df, dummy_marital], axis=1)\n",
    "    del df['marital']\n",
    "    \n",
    "    # combine 'basic.4y', 'basic.6y', 'basic.9y' categories into 'basic'\n",
    "    old_educ_keys = ['unknown', 'illiterate', 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'professional.course', 'university.degree']\n",
    "    new_educ_keys = ['unknown', 'illiterate', 'basic', 'basic', 'basic', 'high.school','professional.course','university.degree']\n",
    "    educ_grp_dict = dict(zip(old_educ_keys, new_educ_keys))\n",
    "    df['education'] = df['education'].map(educ_grp_dict)\n",
    "    educ_dict = dict(zip(new_educ_keys, [i for i in range(1,len(new_educ_keys)+1)]))\n",
    "    df['education'] = df['education'].map(educ_dict)\n",
    "\n",
    "    default_keys = ['no', 'unknown', 'yes']\n",
    "    default_dict = dict(zip(default_keys, [-1,0,1]))\n",
    "    df['default'] = df['default'].map(default_dict)\n",
    "    inv_default_dict = {val:key for key,val in default_dict.items()}\n",
    "\n",
    "    housing_keys = ['no', 'unknown', 'yes']\n",
    "    housing_dict = dict(zip(housing_keys, [-1,0,1]))\n",
    "    df['housing'] = df['housing'].map(housing_dict)\n",
    "    inv_housing_dict = {val:key for key,val in housing_dict.items()}\n",
    "\n",
    "    loan_keys = ['no', 'unknown', 'yes']\n",
    "    loan_dict = dict(zip(loan_keys, [-1,0,1]))\n",
    "    df['loan'] = df['loan'].map(loan_dict)\n",
    "    inv_loan_dict = {val:key for key,val in loan_dict.items()}\n",
    "\n",
    "    cont_keys = ['telephone','cellular']\n",
    "    cont_dict = dict(zip(cont_keys, [0,1]))\n",
    "    df['contact'] = df['contact'].map(cont_dict)\n",
    "    inv_cont_dict = {val:key for key,val in cont_dict.items()}\n",
    "\n",
    "    month_keys = ['jan', 'feb', 'mar', 'apr', 'may', 'jun','jul', 'aug', 'sep', 'oct','nov', 'dec'] #df['month'].unique()\n",
    "    month_dict = dict(zip(month_keys, [i for i in range(1,len(month_keys)+1)]))\n",
    "    df['month'] = df['month'].map(month_dict)\n",
    "    inv_month_dict = {val:key for key,val in month_dict.items()}\n",
    "\n",
    "    week_keys = ['mon','tue','wed','thu','fri']\n",
    "    weekday_dict = dict(zip(week_keys, [i for i in range(1,len(week_keys)+1)]))\n",
    "    df['day_of_week'] = df['day_of_week'].map(weekday_dict)\n",
    "    inv_weekday_dict = {val:key for key,val in weekday_dict.items()}\n",
    "\n",
    "    pout_keys = ['failure', 'nonexistent', 'success']\n",
    "    pout_dict = dict(zip(pout_keys, [-1,0,1]))\n",
    "    df['poutcome'] = df['poutcome'].map(pout_dict)\n",
    "    inv_pout_dict = {val:key for key,val in pout_dict.items()}\n",
    "\n",
    "    y_keys = ['no','yes']\n",
    "    y_dict = dict(zip(y_keys, [0,1]))\n",
    "    df['y'] = df['y'].map(y_dict)\n",
    "    inv_cont_dict = {val:key for key,val in y_dict.items()}\n",
    "    \n",
    "    #delete very skewed dummy features\n",
    "    del df['marital_unknown']\n",
    "    \n",
    "    # Split the data set\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    X_train, y_train = df_train[df.columns[df.columns != 'y']], df_train['y']\n",
    "    X_test, y_test = df_test[df.columns[df.columns != 'y']], df_test['y']\n",
    "    \n",
    "    # instantiate a random forest classifier\n",
    "    rfc = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # search parameter space for optimal parameters\n",
    "    parameters = {'n_estimators':np.linspace(100, 1000, num=5, dtype=int), 'max_depth': np.linspace(10, 101, num=5, dtype=int)}\n",
    "    best_model = model_findparams(X_train, y_train, rfc, parameters)\n",
    "    \n",
    "    # predict and evaluate the model performance\n",
    "    preds, score = model_predict(best_model, X_test, y_test)\n",
    "    accuracy_score = np.mean(preds==y_test)\n",
    "    print(score)\n",
    "    print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
